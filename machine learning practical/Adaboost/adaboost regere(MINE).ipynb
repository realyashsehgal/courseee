{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ce0e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e23e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cardekho_imputated(1).csv\",index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1000ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove Unnecessary Columns\n",
    "df.drop('car_name', axis=1, inplace=True)\n",
    "df.drop('brand', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "85a24192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alto', 'Grand', 'i20', 'Ecosport', 'Wagon R', 'i10', 'Venue',\n",
       "       'Swift', 'Verna', 'Duster', 'Cooper', 'Ciaz', 'C-Class', 'Innova',\n",
       "       'Baleno', 'Swift Dzire', 'Vento', 'Creta', 'City', 'Bolero',\n",
       "       'Fortuner', 'KWID', 'Amaze', 'Santro', 'XUV500', 'KUV100', 'Ignis',\n",
       "       'RediGO', 'Scorpio', 'Marazzo', 'Aspire', 'Figo', 'Vitara',\n",
       "       'Tiago', 'Polo', 'Seltos', 'Celerio', 'GO', '5', 'CR-V',\n",
       "       'Endeavour', 'KUV', 'Jazz', '3', 'A4', 'Tigor', 'Ertiga', 'Safari',\n",
       "       'Thar', 'Hexa', 'Rover', 'Eeco', 'A6', 'E-Class', 'Q7', 'Z4', '6',\n",
       "       'XF', 'X5', 'Hector', 'Civic', 'D-Max', 'Cayenne', 'X1', 'Rapid',\n",
       "       'Freestyle', 'Superb', 'Nexon', 'XUV300', 'Dzire VXI', 'S90',\n",
       "       'WR-V', 'XL6', 'Triber', 'ES', 'Wrangler', 'Camry', 'Elantra',\n",
       "       'Yaris', 'GL-Class', '7', 'S-Presso', 'Dzire LXI', 'Aura', 'XC',\n",
       "       'Ghibli', 'Continental', 'CR', 'Kicks', 'S-Class', 'Tucson',\n",
       "       'Harrier', 'X3', 'Octavia', 'Compass', 'CLS', 'redi-GO', 'Glanza',\n",
       "       'Macan', 'X4', 'Dzire ZXI', 'XC90', 'F-PACE', 'A8', 'MUX',\n",
       "       'GTC4Lusso', 'GLS', 'X-Trail', 'XE', 'XC60', 'Panamera', 'Alturas',\n",
       "       'Altroz', 'NX', 'Carnival', 'C', 'RX', 'Ghost', 'Quattroporte',\n",
       "       'Gurkha'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb246ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Numerical Features : 7\n",
      "Num of Categorical Features : 4\n",
      "Num of Discrete Features : 2\n",
      "Num of Continuous Features : 5\n"
     ]
    }
   ],
   "source": [
    "## Getting All Different Types OF Features\n",
    "num_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "print('Num of Numerical Features :', len(num_features))\n",
    "cat_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "print('Num of Categorical Features :', len(cat_features))\n",
    "discrete_features=[feature for feature in num_features if len(df[feature].unique())<=25]\n",
    "print('Num of Discrete Features :',len(discrete_features))\n",
    "continuous_features=[feature for feature in num_features if feature not in discrete_features]\n",
    "print('Num of Continuous Features :',len(continuous_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e41b4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indpendent and dependent features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['selling_price'], axis=1)\n",
    "y = df['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "637a5dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdfb9664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['model'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "584ba14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "i20             906\n",
       "Swift Dzire     890\n",
       "Swift           781\n",
       "Alto            778\n",
       "City            757\n",
       "               ... \n",
       "Altroz            1\n",
       "C                 1\n",
       "Ghost             1\n",
       "Quattroporte      1\n",
       "Gurkha            1\n",
       "Name: count, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bae1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "X['model']=le.fit_transform(X['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d72335f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['seller_type'].unique()),len(df['fuel_type'].unique()),len(df['transmission_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab7c0997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "onehot_columns = ['seller_type','fuel_type','transmission_type']\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, onehot_columns),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features)\n",
    "        \n",
    "    ],remainder='passthrough'\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "627b75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af634aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5922c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eec73771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6ce69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d5b0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a Function to Evaluate Model\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c362c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553855.6665\n",
      "- Mean Absolute Error: 268101.6071\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502543.5930\n",
      "- Mean Absolute Error: 279618.5794\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553855.6710\n",
      "- Mean Absolute Error: 268099.2226\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502542.6696\n",
      "- Mean Absolute Error: 279614.7461\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 553856.3160\n",
      "- Mean Absolute Error: 268059.8015\n",
      "- R2 Score: 0.6218\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 502533.8230\n",
      "- Mean Absolute Error: 279557.2169\n",
      "- R2 Score: 0.6645\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 325873.0088\n",
      "- Mean Absolute Error: 91425.4705\n",
      "- R2 Score: 0.8691\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 253024.3951\n",
      "- Mean Absolute Error: 112526.3461\n",
      "- R2 Score: 0.9150\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 20797.2352\n",
      "- Mean Absolute Error: 5164.8199\n",
      "- R2 Score: 0.9995\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 306103.7338\n",
      "- Mean Absolute Error: 125429.9032\n",
      "- R2 Score: 0.8755\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 133917.8507\n",
      "- Mean Absolute Error: 40044.3734\n",
      "- R2 Score: 0.9779\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 229023.8468\n",
      "- Mean Absolute Error: 102165.2875\n",
      "- R2 Score: 0.9303\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 445319.9722\n",
      "- Mean Absolute Error: 318295.9822\n",
      "- R2 Score: 0.7555\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 521399.0047\n",
      "- Mean Absolute Error: 341530.7303\n",
      "- R2 Score: 0.6389\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Beginning Model Training\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"Adaboost Regressor\":AdaBoostRegressor()\n",
    "   \n",
    "}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a671f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize few parameter for Hyperparamter tuning\n",
    "knn_params = {\"n_neighbors\": [2, 3, 10, 20, 40, 50]}\n",
    "rf_params = {\"max_depth\": [5, 8, 15, None, 10],\n",
    "             \"max_features\": [5, 7, \"auto\", 8],\n",
    "             \"min_samples_split\": [2, 8, 15, 20],\n",
    "             \"n_estimators\": [100, 200, 500, 1000]}\n",
    "\n",
    "ada_params={\n",
    "    \"n_estimators\":[50,60,70,80],\n",
    "    \"loss\":['linear','square','exponential']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3f875f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models list for Hyperparameter tuning\n",
    "randomcv_models = [('KNN', KNeighborsRegressor(), knn_params),\n",
    "                   (\"RF\", RandomForestRegressor(), rf_params),\n",
    "                   (\"Adaboost\",AdaBoostRegressor(),ada_params)\n",
    "                   \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2e576059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model, params \u001b[38;5;129;01min\u001b[39;00m randomcv_models:\n\u001b[0;32m      6\u001b[0m     random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      7\u001b[0m                                    param_distributions\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m      8\u001b[0m                                    n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                    cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     11\u001b[0m                                    n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m     \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     model_param[name] \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m model_param:\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1959\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1958\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yashs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Hyperparameter Tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_param = {}\n",
    "for name, model, params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=100,\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   n_jobs=-1)\n",
    "    random.fit(X_train, y_train)\n",
    "    model_param[name] = random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"---------------- Best Params for {model_name} -------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bb547172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 136646.8365\n",
      "- Mean Absolute Error: 56036.9093\n",
      "- R2 Score: 0.9770\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 208173.0178\n",
      "- Mean Absolute Error: 97401.3830\n",
      "- R2 Score: 0.9424\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 363460.7706\n",
      "- Mean Absolute Error: 103472.0474\n",
      "- R2 Score: 0.8371\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 263888.0623\n",
      "- Mean Absolute Error: 117496.2131\n",
      "- R2 Score: 0.9075\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 407372.1181\n",
      "- Mean Absolute Error: 267989.8457\n",
      "- R2 Score: 0.7954\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 437447.9384\n",
      "- Mean Absolute Error: 286759.2087\n",
      "- R2 Score: 0.7458\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Retraining the models with best parameters\n",
    "models = {\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(n_estimators=500, min_samples_split=2, max_features=5, max_depth=15, \n",
    "                                                     n_jobs=-1),\n",
    "     \"K-Neighbors Regressor\": KNeighborsRegressor(n_neighbors=10, n_jobs=-1),\n",
    "     \"Adaboost\":AdaBoostRegressor(n_estimators=60,loss='linear')\n",
    "    \n",
    "}\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    model_train_mae , model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_mae , model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "    print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "    print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dc850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
